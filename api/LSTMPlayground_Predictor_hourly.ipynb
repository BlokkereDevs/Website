{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f87a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from operator import eq\n",
    "import pandas as pd\n",
    "#import pandas_ta as ta\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "## IMPORT SKLEARN\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, plot_confusion_matrix, plot_roc_curve, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance, Booster, plot_tree, to_graphviz, DMatrix\n",
    "\n",
    "import numpy as np\n",
    "plt.style.use('seaborn')\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b216bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TENSORFLOW AND KERAS\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, LSTM\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop \n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db1e7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def set_seeds(seed=2022): \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tensorflow.random.set_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6dfd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>2871.300049</td>\n",
       "      <td>2921.350098</td>\n",
       "      <td>2685.610107</td>\n",
       "      <td>2718.260010</td>\n",
       "      <td>2718.260010</td>\n",
       "      <td>1324669952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-02</th>\n",
       "      <td>2727.129883</td>\n",
       "      <td>2762.530029</td>\n",
       "      <td>2668.590088</td>\n",
       "      <td>2710.669922</td>\n",
       "      <td>2710.669922</td>\n",
       "      <td>1094950016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-03</th>\n",
       "      <td>2709.560059</td>\n",
       "      <td>2813.310059</td>\n",
       "      <td>2685.139893</td>\n",
       "      <td>2804.729980</td>\n",
       "      <td>2804.729980</td>\n",
       "      <td>804796992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04</th>\n",
       "      <td>2806.929932</td>\n",
       "      <td>2899.330078</td>\n",
       "      <td>2743.719971</td>\n",
       "      <td>2895.889893</td>\n",
       "      <td>2895.889893</td>\n",
       "      <td>1002120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-05</th>\n",
       "      <td>2897.629883</td>\n",
       "      <td>3290.010010</td>\n",
       "      <td>2874.830078</td>\n",
       "      <td>3252.909912</td>\n",
       "      <td>3252.909912</td>\n",
       "      <td>1945699968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2017-08-01  2871.300049  2921.350098  2685.610107  2718.260010  2718.260010   \n",
       "2017-08-02  2727.129883  2762.530029  2668.590088  2710.669922  2710.669922   \n",
       "2017-08-03  2709.560059  2813.310059  2685.139893  2804.729980  2804.729980   \n",
       "2017-08-04  2806.929932  2899.330078  2743.719971  2895.889893  2895.889893   \n",
       "2017-08-05  2897.629883  3290.010010  2874.830078  3252.909912  3252.909912   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "2017-08-01  1324669952  \n",
       "2017-08-02  1094950016  \n",
       "2017-08-03   804796992  \n",
       "2017-08-04  1002120000  \n",
       "2017-08-05  1945699968  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equityData = data = yf.download('BTC-USD', start=\"2017-08-01\",end=\"2022-10-03\")\n",
    "equityData.dropna(inplace=True)\n",
    "equityData.drop(index=equityData.index[0], axis=0, inplace=True)\n",
    "equityData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dae3d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "equityData.to_excel('StockDataCSV/BTCBotData.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a70f12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-28</th>\n",
       "      <td>19104.621094</td>\n",
       "      <td>19688.343750</td>\n",
       "      <td>18553.296875</td>\n",
       "      <td>19426.720703</td>\n",
       "      <td>19426.720703</td>\n",
       "      <td>53071298734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-29</th>\n",
       "      <td>19427.779297</td>\n",
       "      <td>19589.265625</td>\n",
       "      <td>18924.353516</td>\n",
       "      <td>19573.050781</td>\n",
       "      <td>19573.050781</td>\n",
       "      <td>41037843771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-30</th>\n",
       "      <td>19573.431641</td>\n",
       "      <td>20109.849609</td>\n",
       "      <td>19265.662109</td>\n",
       "      <td>19431.789062</td>\n",
       "      <td>19431.789062</td>\n",
       "      <td>43975248085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>19431.105469</td>\n",
       "      <td>19471.154297</td>\n",
       "      <td>19231.082031</td>\n",
       "      <td>19312.095703</td>\n",
       "      <td>19312.095703</td>\n",
       "      <td>18719537670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02</th>\n",
       "      <td>19311.849609</td>\n",
       "      <td>19370.308594</td>\n",
       "      <td>18970.621094</td>\n",
       "      <td>19044.107422</td>\n",
       "      <td>19044.107422</td>\n",
       "      <td>20765955327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close  \\\n",
       "Date                                                                 \n",
       "2022-09-28  19104.621094  19688.343750  18553.296875  19426.720703   \n",
       "2022-09-29  19427.779297  19589.265625  18924.353516  19573.050781   \n",
       "2022-09-30  19573.431641  20109.849609  19265.662109  19431.789062   \n",
       "2022-10-01  19431.105469  19471.154297  19231.082031  19312.095703   \n",
       "2022-10-02  19311.849609  19370.308594  18970.621094  19044.107422   \n",
       "\n",
       "               Adj Close       Volume  \n",
       "Date                                   \n",
       "2022-09-28  19426.720703  53071298734  \n",
       "2022-09-29  19573.050781  41037843771  \n",
       "2022-09-30  19431.789062  43975248085  \n",
       "2022-10-01  19312.095703  18719537670  \n",
       "2022-10-02  19044.107422  20765955327  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equityData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88016280",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Path to store results\n",
    "\n",
    "results_path = Path('results', 'lstm_time_series')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c675d611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1889, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = equityData['Adj Close']\n",
    "\n",
    "data = data.to_numpy()\n",
    "data = np.reshape(data, (-1, 1))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85fcf61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization \n",
    "plt.figure(figsize=(14,6))\n",
    "plt.title('BTC Price')\n",
    "plt.plot(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97fa2943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Size 1511, 378\n"
     ]
    }
   ],
   "source": [
    "#### TRAIN - TEST SPLIT\n",
    "# Splitting the datasets into training and testing data.\n",
    "train_data, test_data = train_test_split(data, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Output the train and test data size\n",
    "print(f\"Train and Test Size {len(train_data)}, {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4715e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PREPROCESSING\n",
    "# Scale the features MinMax for training and test datasets\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_data = scaler.fit_transform(train_data)\n",
    "scaled_test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6dac445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GENERATE SEQUENCE\n",
    "\n",
    "def generate_sequence(data, sequence_length=60):\n",
    "    \n",
    "    # create X & y data array\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i - sequence_length:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    \n",
    "    # Converting x_train and y_train to Numpy arrays\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d424bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence length\n",
    "lookback = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f041a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1451, 60), y_train (1451,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = generate_sequence(data=scaled_train_data, sequence_length=lookback)\n",
    "print(f'X_train: {X_train.shape}, y_train {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "216e102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (318, 60), y_test (318,)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = generate_sequence(data=scaled_test_data, sequence_length=lookback)\n",
    "print(f'X_test: {X_test.shape}, y_test {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40b78176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (1451, 60, 1), y_train (1451, 1)\n"
     ]
    }
   ],
   "source": [
    "#### RESHAPE\n",
    "\n",
    "# reshaping array\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "y_train = y_train[:, np.newaxis] \n",
    "\n",
    "# check the array size\n",
    "print(f'X_train Shape: {X_train.shape}, y_train {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "213eb7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test Shape: (318, 60, 1), y_test (318, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshaping test array\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "y_test = y_test[:, np.newaxis] \n",
    "\n",
    "# check the test array size\n",
    "print(f'X_test Shape: {X_test.shape}, y_test {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac39a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE THE MODEL\n",
    "def create_model(hu=256, lookback=60):\n",
    "\n",
    "    tensorflow.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hu, input_shape=(lookback, 1), activation = 'relu', return_sequences=False, name='LSTM'))\n",
    "    model.add(Dense(units=1, name='Output'))              # can also specify linear activation function \n",
    "    \n",
    "    # specify optimizer separately (preferred method))\n",
    "#     opt = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    opt = Adam(lr=0.001, epsilon=1e-08, decay=0.0)       # adam optimizer seems to perform better for a single lstm\n",
    "    \n",
    "    # model compilation\n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34933fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm network\n",
    "model = create_model(hu=10, lookback=lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f8d9fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM (LSTM)                 (None, 10)                480       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "907ec0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TRAIN THE MODEL\n",
    "# Specify callback functions\n",
    "model_path = (results_path / 'model.h5').as_posix()\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=10, monitor='loss', mode='min', verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=model_path, verbose=1, monitor='loss', save_best_only=True),\n",
    "    TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06b960a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0277 - mae: 0.1012\n",
      "Epoch 1: loss improved from inf to 0.03164, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 6s 30ms/step - loss: 0.0316 - mae: 0.1101\n",
      "Epoch 2/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0086 - mae: 0.0621\n",
      "Epoch 2: loss improved from 0.03164 to 0.00965, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.0097 - mae: 0.0662\n",
      "Epoch 3/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1568 - mae: 0.1486\n",
      "Epoch 3: loss did not improve from 0.00965\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.1525 - mae: 0.1471\n",
      "Epoch 4/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0113 - mae: 0.0608   \n",
      "Epoch 4: loss did not improve from 0.00965\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.0136 - mae: 0.0678\n",
      "Epoch 5/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0120 - mae: 0.0604   \n",
      "Epoch 5: loss did not improve from 0.00965\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.0143 - mae: 0.0674\n",
      "Epoch 6/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0108 - mae: 0.0569   \n",
      "Epoch 6: loss did not improve from 0.00965\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.0129 - mae: 0.0637\n",
      "Epoch 7/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0097 - mae: 0.0550   \n",
      "Epoch 7: loss did not improve from 0.00965\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.0116 - mae: 0.0614\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0106 - mae: 0.0612   \n",
      "Epoch 8: loss did not improve from 0.00965\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.0106 - mae: 0.0612\n",
      "Epoch 9/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0083 - mae: 0.0565\n",
      "Epoch 9: loss did not improve from 0.00965\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.0099 - mae: 0.0621\n",
      "Epoch 10/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0078 - mae: 0.0578\n",
      "Epoch 10: loss improved from 0.00965 to 0.00929, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.0093 - mae: 0.0631\n",
      "Epoch 11/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0075 - mae: 0.0590\n",
      "Epoch 11: loss improved from 0.00929 to 0.00881, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.0088 - mae: 0.0639\n",
      "Epoch 12/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0072 - mae: 0.0599\n",
      "Epoch 12: loss improved from 0.00881 to 0.00842, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0084 - mae: 0.0645\n",
      "Epoch 13/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0069 - mae: 0.0604\n",
      "Epoch 13: loss improved from 0.00842 to 0.00807, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0081 - mae: 0.0648\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0078 - mae: 0.0647\n",
      "Epoch 14: loss improved from 0.00807 to 0.00775, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0078 - mae: 0.0647\n",
      "Epoch 15/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0057 - mae: 0.0560\n",
      "Epoch 15: loss improved from 0.00775 to 0.00745, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0075 - mae: 0.0644\n",
      "Epoch 16/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0055 - mae: 0.0559\n",
      "Epoch 16: loss improved from 0.00745 to 0.00717, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0072 - mae: 0.0638\n",
      "Epoch 17/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0056 - mae: 0.0568\n",
      "Epoch 17: loss improved from 0.00717 to 0.00690, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0069 - mae: 0.0629\n",
      "Epoch 18/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0052 - mae: 0.0548\n",
      "Epoch 18: loss improved from 0.00690 to 0.00663, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0066 - mae: 0.0619\n",
      "Epoch 19/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0052 - mae: 0.0549\n",
      "Epoch 19: loss improved from 0.00663 to 0.00638, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0064 - mae: 0.0606\n",
      "Epoch 20/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0048 - mae: 0.0526\n",
      "Epoch 20: loss improved from 0.00638 to 0.00613, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0061 - mae: 0.0593\n",
      "Epoch 21/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0046 - mae: 0.0513\n",
      "Epoch 21: loss improved from 0.00613 to 0.00590, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0059 - mae: 0.0579\n",
      "Epoch 22/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0046 - mae: 0.0511\n",
      "Epoch 22: loss improved from 0.00590 to 0.00568, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0057 - mae: 0.0564\n",
      "Epoch 23/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0042 - mae: 0.0483\n",
      "Epoch 23: loss improved from 0.00568 to 0.00547, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0055 - mae: 0.0549\n",
      "Epoch 24/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0043 - mae: 0.0483\n",
      "Epoch 24: loss improved from 0.00547 to 0.00528, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0053 - mae: 0.0533\n",
      "Epoch 25/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0042 - mae: 0.0468\n",
      "Epoch 25: loss improved from 0.00528 to 0.00511, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0051 - mae: 0.0518\n",
      "Epoch 26/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0037 - mae: 0.0433\n",
      "Epoch 26: loss improved from 0.00511 to 0.00494, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0049 - mae: 0.0503\n",
      "Epoch 27/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0035 - mae: 0.0415\n",
      "Epoch 27: loss improved from 0.00494 to 0.00479, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0048 - mae: 0.0487\n",
      "Epoch 28/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0033 - mae: 0.0393\n",
      "Epoch 28: loss improved from 0.00479 to 0.00462, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0046 - mae: 0.0467\n",
      "Epoch 29/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0035 - mae: 0.0371    \n",
      "Epoch 29: loss improved from 0.00462 to 0.00430, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0043 - mae: 0.0421\n",
      "Epoch 30/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0032 - mae: 0.0314    \n",
      "Epoch 30: loss improved from 0.00430 to 0.00390, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0039 - mae: 0.0363\n",
      "Epoch 31/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0031 - mae: 0.0304    \n",
      "Epoch 31: loss improved from 0.00390 to 0.00373, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0037 - mae: 0.0349\n",
      "Epoch 32/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0031 - mae: 0.0301    \n",
      "Epoch 32: loss improved from 0.00373 to 0.00362, saving model to results/lstm_time_series\\model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0036 - mae: 0.0343\n",
      "Epoch 33/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0021 - mae: 0.0253    \n",
      "Epoch 33: loss improved from 0.00362 to 0.00353, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0035 - mae: 0.0337\n",
      "Epoch 34/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0030 - mae: 0.0296    \n",
      "Epoch 34: loss improved from 0.00353 to 0.00345, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0034 - mae: 0.0333\n",
      "Epoch 35/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0020 - mae: 0.0247    \n",
      "Epoch 35: loss improved from 0.00345 to 0.00338, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0034 - mae: 0.0329\n",
      "Epoch 36/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0029 - mae: 0.0292    \n",
      "Epoch 36: loss improved from 0.00338 to 0.00331, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0033 - mae: 0.0326\n",
      "Epoch 37/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0244    \n",
      "Epoch 37: loss improved from 0.00331 to 0.00324, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0032 - mae: 0.0324\n",
      "Epoch 38/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0028 - mae: 0.0290    \n",
      "Epoch 38: loss improved from 0.00324 to 0.00318, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0032 - mae: 0.0322\n",
      "Epoch 39/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0027 - mae: 0.0289    \n",
      "Epoch 39: loss improved from 0.00318 to 0.00312, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0031 - mae: 0.0320\n",
      "Epoch 40/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0027 - mae: 0.0288    \n",
      "Epoch 40: loss improved from 0.00312 to 0.00306, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0031 - mae: 0.0318\n",
      "Epoch 41/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0027 - mae: 0.0287    \n",
      "Epoch 41: loss improved from 0.00306 to 0.00301, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0030 - mae: 0.0317\n",
      "Epoch 42/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0017 - mae: 0.0242    \n",
      "Epoch 42: loss improved from 0.00301 to 0.00296, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0030 - mae: 0.0315\n",
      "Epoch 43/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0026 - mae: 0.0286    \n",
      "Epoch 43: loss improved from 0.00296 to 0.00291, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0029 - mae: 0.0314\n",
      "Epoch 44/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0285    \n",
      "Epoch 44: loss improved from 0.00291 to 0.00286, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0029 - mae: 0.0312\n",
      "Epoch 45/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0284    \n",
      "Epoch 45: loss improved from 0.00286 to 0.00281, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0028 - mae: 0.0310\n",
      "Epoch 46/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0283    \n",
      "Epoch 46: loss improved from 0.00281 to 0.00276, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0028 - mae: 0.0308\n",
      "Epoch 47/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0024 - mae: 0.0281    \n",
      "Epoch 47: loss improved from 0.00276 to 0.00271, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0027 - mae: 0.0307\n",
      "Epoch 48/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0024 - mae: 0.0280    \n",
      "Epoch 48: loss improved from 0.00271 to 0.00266, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0027 - mae: 0.0305\n",
      "Epoch 49/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0023 - mae: 0.0279    \n",
      "Epoch 49: loss improved from 0.00266 to 0.00261, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0026 - mae: 0.0303\n",
      "Epoch 50/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0023 - mae: 0.0277    \n",
      "Epoch 50: loss improved from 0.00261 to 0.00257, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0026 - mae: 0.0301\n",
      "Epoch 51/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0023 - mae: 0.0276    \n",
      "Epoch 51: loss improved from 0.00257 to 0.00252, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0025 - mae: 0.0299\n",
      "Epoch 52/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0015 - mae: 0.0236    \n",
      "Epoch 52: loss improved from 0.00252 to 0.00247, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0025 - mae: 0.0297\n",
      "Epoch 53/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0023 - mae: 0.0281    \n",
      "Epoch 53: loss improved from 0.00247 to 0.00243, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0024 - mae: 0.0295\n",
      "Epoch 54/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0015 - mae: 0.0235    \n",
      "Epoch 54: loss improved from 0.00243 to 0.00238, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0024 - mae: 0.0294\n",
      "Epoch 55/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0014 - mae: 0.0235    \n",
      "Epoch 55: loss improved from 0.00238 to 0.00234, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0023 - mae: 0.0292\n",
      "Epoch 56/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0021 - mae: 0.0269    \n",
      "Epoch 56: loss improved from 0.00234 to 0.00229, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0023 - mae: 0.0290\n",
      "Epoch 57/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0267    \n",
      "Epoch 57: loss improved from 0.00229 to 0.00224, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0022 - mae: 0.0288\n",
      "Epoch 58/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0273    \n",
      "Epoch 58: loss improved from 0.00224 to 0.00219, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0022 - mae: 0.0286\n",
      "Epoch 59/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0264    \n",
      "Epoch 59: loss improved from 0.00219 to 0.00214, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0021 - mae: 0.0283\n",
      "Epoch 60/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0013 - mae: 0.0231    \n",
      "Epoch 60: loss improved from 0.00214 to 0.00208, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0021 - mae: 0.0281\n",
      "Epoch 61/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0018 - mae: 0.0260    \n",
      "Epoch 61: loss improved from 0.00208 to 0.00203, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0020 - mae: 0.0279\n",
      "Epoch 62/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0013 - mae: 0.0230    \n",
      "Epoch 62: loss improved from 0.00203 to 0.00197, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0020 - mae: 0.0277\n",
      "Epoch 63/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0017 - mae: 0.0257    \n",
      "Epoch 63: loss improved from 0.00197 to 0.00192, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0019 - mae: 0.0275\n",
      "Epoch 64/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0013 - mae: 0.0230    \n",
      "Epoch 64: loss improved from 0.00192 to 0.00186, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0019 - mae: 0.0273\n",
      "Epoch 65/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0016 - mae: 0.0253    \n",
      "Epoch 65: loss improved from 0.00186 to 0.00180, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0018 - mae: 0.0270\n",
      "Epoch 66/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0016 - mae: 0.0252    \n",
      "Epoch 66: loss improved from 0.00180 to 0.00174, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0017 - mae: 0.0269\n",
      "Epoch 67/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0015 - mae: 0.0253    \n",
      "Epoch 67: loss improved from 0.00174 to 0.00169, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0017 - mae: 0.0269\n",
      "Epoch 68/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0015 - mae: 0.0254    \n",
      "Epoch 68: loss improved from 0.00169 to 0.00165, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0017 - mae: 0.0271\n",
      "Epoch 69/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0015 - mae: 0.0254    \n",
      "Epoch 69: loss improved from 0.00165 to 0.00162, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0016 - mae: 0.0270\n",
      "Epoch 70/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.0012 - mae: 0.0233    \n",
      "Epoch 70: loss improved from 0.00162 to 0.00158, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0016 - mae: 0.0267\n",
      "Epoch 71/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0014 - mae: 0.0247    \n",
      "Epoch 71: loss improved from 0.00158 to 0.00154, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0015 - mae: 0.0263\n",
      "Epoch 72/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0013 - mae: 0.0241    \n",
      "Epoch 72: loss improved from 0.00154 to 0.00149, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0015 - mae: 0.0257\n",
      "Epoch 73/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0013 - mae: 0.0237    \n",
      "Epoch 73: loss improved from 0.00149 to 0.00146, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0015 - mae: 0.0253\n",
      "Epoch 74/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0013 - mae: 0.0231    \n",
      "Epoch 74: loss improved from 0.00146 to 0.00142, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0014 - mae: 0.0247\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0242    \n",
      "Epoch 75: loss improved from 0.00142 to 0.00139, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0014 - mae: 0.0242\n",
      "Epoch 76/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 9.6268e-04 - mae: 0.0202\n",
      "Epoch 76: loss improved from 0.00139 to 0.00136, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0014 - mae: 0.0238\n",
      "Epoch 77/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0013 - mae: 0.0228    \n",
      "Epoch 77: loss improved from 0.00136 to 0.00134, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0013 - mae: 0.0234\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0232    \n",
      "Epoch 78: loss improved from 0.00134 to 0.00132, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0013 - mae: 0.0232\n",
      "Epoch 79/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 9.0608e-04 - mae: 0.0192\n",
      "Epoch 79: loss improved from 0.00132 to 0.00129, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0013 - mae: 0.0229\n",
      "Epoch 80/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0211    \n",
      "Epoch 80: loss improved from 0.00129 to 0.00128, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0013 - mae: 0.0227\n",
      "Epoch 81/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0209    \n",
      "Epoch 81: loss improved from 0.00128 to 0.00126, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0013 - mae: 0.0225\n",
      "Epoch 82/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0208    \n",
      "Epoch 82: loss improved from 0.00126 to 0.00124, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0012 - mae: 0.0224\n",
      "Epoch 83/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0206    \n",
      "Epoch 83: loss improved from 0.00124 to 0.00123, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0012 - mae: 0.0222\n",
      "Epoch 84/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0205    \n",
      "Epoch 84: loss improved from 0.00123 to 0.00122, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0012 - mae: 0.0221\n",
      "Epoch 85/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0204    \n",
      "Epoch 85: loss improved from 0.00122 to 0.00120, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0012 - mae: 0.0219\n",
      "Epoch 86/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0202    \n",
      "Epoch 86: loss improved from 0.00120 to 0.00119, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0012 - mae: 0.0218\n",
      "Epoch 87/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0201    \n",
      "Epoch 87: loss improved from 0.00119 to 0.00118, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0012 - mae: 0.0217\n",
      "Epoch 88/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0010 - mae: 0.0200    \n",
      "Epoch 88: loss improved from 0.00118 to 0.00117, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0012 - mae: 0.0216\n",
      "Epoch 89/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0010 - mae: 0.0199    \n",
      "Epoch 89: loss improved from 0.00117 to 0.00116, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0012 - mae: 0.0215\n",
      "Epoch 90/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0010 - mae: 0.0198    \n",
      "Epoch 90: loss improved from 0.00116 to 0.00114, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0214\n",
      "Epoch 91/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0010 - mae: 0.0198    \n",
      "Epoch 91: loss improved from 0.00114 to 0.00114, saving model to results/lstm_time_series\\model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0213\n",
      "Epoch 92/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 7.9159e-04 - mae: 0.0177\n",
      "Epoch 92: loss improved from 0.00114 to 0.00113, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0212\n",
      "Epoch 93/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0010 - mae: 0.0196    \n",
      "Epoch 93: loss improved from 0.00113 to 0.00112, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0211\n",
      "Epoch 94/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0010 - mae: 0.0195    \n",
      "Epoch 94: loss improved from 0.00112 to 0.00111, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0210\n",
      "Epoch 95/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.9395e-04 - mae: 0.0195\n",
      "Epoch 95: loss improved from 0.00111 to 0.00110, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0209\n",
      "Epoch 96/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.8648e-04 - mae: 0.0194\n",
      "Epoch 96: loss improved from 0.00110 to 0.00109, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0011 - mae: 0.0209\n",
      "Epoch 97/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.8026e-04 - mae: 0.0193\n",
      "Epoch 97: loss improved from 0.00109 to 0.00108, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0208\n",
      "Epoch 98/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.7351e-04 - mae: 0.0193\n",
      "Epoch 98: loss improved from 0.00108 to 0.00107, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0207\n",
      "Epoch 99/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.6743e-04 - mae: 0.0192\n",
      "Epoch 99: loss improved from 0.00107 to 0.00107, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0206\n",
      "Epoch 100/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.6127e-04 - mae: 0.0191\n",
      "Epoch 100: loss improved from 0.00107 to 0.00106, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0011 - mae: 0.0206\n",
      "Epoch 101/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.5593e-04 - mae: 0.0191\n",
      "Epoch 101: loss improved from 0.00106 to 0.00105, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0011 - mae: 0.0205\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0204    \n",
      "Epoch 102: loss improved from 0.00105 to 0.00105, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0010 - mae: 0.0204\n",
      "Epoch 103/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.4450e-04 - mae: 0.0190\n",
      "Epoch 103: loss improved from 0.00105 to 0.00104, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0010 - mae: 0.0204\n",
      "Epoch 104/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.3938e-04 - mae: 0.0189\n",
      "Epoch 104: loss improved from 0.00104 to 0.00103, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0010 - mae: 0.0203\n",
      "Epoch 105/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.3460e-04 - mae: 0.0189\n",
      "Epoch 105: loss improved from 0.00103 to 0.00103, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0010 - mae: 0.0203\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0202    \n",
      "Epoch 106: loss improved from 0.00103 to 0.00102, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0010 - mae: 0.0202\n",
      "Epoch 107/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 9.8935e-04 - mae: 0.0197\n",
      "Epoch 107: loss improved from 0.00102 to 0.00102, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0010 - mae: 0.0202\n",
      "Epoch 108/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.2051e-04 - mae: 0.0187\n",
      "Epoch 108: loss improved from 0.00102 to 0.00101, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0010 - mae: 0.0201\n",
      "Epoch 109/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 9.7912e-04 - mae: 0.0196\n",
      "Epoch 109: loss improved from 0.00101 to 0.00101, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0010 - mae: 0.0201\n",
      "Epoch 110/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 7.1362e-04 - mae: 0.0168\n",
      "Epoch 110: loss improved from 0.00101 to 0.00100, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0010 - mae: 0.0200\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 9.9627e-04 - mae: 0.0200\n",
      "Epoch 111: loss improved from 0.00100 to 0.00100, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 9.9627e-04 - mae: 0.0200\n",
      "Epoch 112/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.0261e-04 - mae: 0.0186\n",
      "Epoch 112: loss improved from 0.00100 to 0.00099, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 9.9102e-04 - mae: 0.0199\n",
      "Epoch 113/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 9.5988e-04 - mae: 0.0195\n",
      "Epoch 113: loss improved from 0.00099 to 0.00099, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 9.8669e-04 - mae: 0.0199\n",
      "Epoch 114/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.9435e-04 - mae: 0.0185\n",
      "Epoch 114: loss improved from 0.00099 to 0.00098, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 9.8153e-04 - mae: 0.0198\n",
      "Epoch 115/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 9.5150e-04 - mae: 0.0194\n",
      "Epoch 115: loss improved from 0.00098 to 0.00098, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 9.7792e-04 - mae: 0.0198\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 9.7272e-04 - mae: 0.0198\n",
      "Epoch 116: loss improved from 0.00098 to 0.00097, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 9.7272e-04 - mae: 0.0198\n",
      "Epoch 117/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 9.4361e-04 - mae: 0.0193\n",
      "Epoch 117: loss improved from 0.00097 to 0.00097, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 9.6967e-04 - mae: 0.0197\n",
      "Epoch 118/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.8902e-04 - mae: 0.0165\n",
      "Epoch 118: loss improved from 0.00097 to 0.00096, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 9.6445e-04 - mae: 0.0197\n",
      "Epoch 119/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.7774e-04 - mae: 0.0183\n",
      "Epoch 119: loss improved from 0.00096 to 0.00096, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.6192e-04 - mae: 0.0197\n",
      "Epoch 120/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.7215e-04 - mae: 0.0182\n",
      "Epoch 120: loss improved from 0.00096 to 0.00096, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.5628e-04 - mae: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.7141e-04 - mae: 0.0182\n",
      "Epoch 121: loss improved from 0.00096 to 0.00095, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.5463e-04 - mae: 0.0196\n",
      "Epoch 122/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.6521e-04 - mae: 0.0181\n",
      "Epoch 122: loss improved from 0.00095 to 0.00095, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.4857e-04 - mae: 0.0195\n",
      "Epoch 123/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.6567e-04 - mae: 0.0182\n",
      "Epoch 123: loss improved from 0.00095 to 0.00095, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.4800e-04 - mae: 0.0195\n",
      "Epoch 124/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.5886e-04 - mae: 0.0180\n",
      "Epoch 124: loss improved from 0.00095 to 0.00094, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.4136e-04 - mae: 0.0194\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 9.4139e-04 - mae: 0.0194\n",
      "Epoch 125: loss did not improve from 0.00094\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.4139e-04 - mae: 0.0194\n",
      "Epoch 126/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 9.0887e-04 - mae: 0.0189\n",
      "Epoch 126: loss improved from 0.00094 to 0.00093, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.3347e-04 - mae: 0.0193\n",
      "Epoch 127/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.6936e-04 - mae: 0.0162\n",
      "Epoch 127: loss did not improve from 0.00093\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.3658e-04 - mae: 0.0194\n",
      "Epoch 128/500\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 4.2502e-04 - mae: 0.0137\n",
      "Epoch 128: loss improved from 0.00093 to 0.00093, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 9.2622e-04 - mae: 0.0192\n",
      "Epoch 129/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.6717e-04 - mae: 0.0162\n",
      "Epoch 129: loss did not improve from 0.00093\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.3345e-04 - mae: 0.0194\n",
      "Epoch 130/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.5474e-04 - mae: 0.0158\n",
      "Epoch 130: loss improved from 0.00093 to 0.00092, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.1859e-04 - mae: 0.0190\n",
      "Epoch 131/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.6571e-04 - mae: 0.0163\n",
      "Epoch 131: loss did not improve from 0.00092\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.3192e-04 - mae: 0.0194\n",
      "Epoch 132/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.2954e-04 - mae: 0.0174\n",
      "Epoch 132: loss improved from 0.00092 to 0.00091, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 9.1092e-04 - mae: 0.0188\n",
      "Epoch 133/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.5832e-04 - mae: 0.0182\n",
      "Epoch 133: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.3583e-04 - mae: 0.0196\n",
      "Epoch 134/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.4017e-04 - mae: 0.0153\n",
      "Epoch 134: loss improved from 0.00091 to 0.00091, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 9.0515e-04 - mae: 0.0186\n",
      "Epoch 135/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.7412e-04 - mae: 0.0186\n",
      "Epoch 135: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.4991e-04 - mae: 0.0199\n",
      "Epoch 136/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.2390e-04 - mae: 0.0169\n",
      "Epoch 136: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.0519e-04 - mae: 0.0183\n",
      "Epoch 137/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.1161e-04 - mae: 0.0192\n",
      "Epoch 137: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.8509e-04 - mae: 0.0205\n",
      "Epoch 138/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.3545e-04 - mae: 0.0167\n",
      "Epoch 138: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.1600e-04 - mae: 0.0181\n",
      "Epoch 139/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 9.6844e-04 - mae: 0.0201\n",
      "Epoch 139: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0010 - mae: 0.0213\n",
      "Epoch 140/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 9.0419e-04 - mae: 0.0175\n",
      "Epoch 140: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.2491e-04 - mae: 0.0180\n",
      "Epoch 141/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 7.2390e-04 - mae: 0.0183\n",
      "Epoch 141: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0011 - mae: 0.0216\n",
      "Epoch 142/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.3103e-04 - mae: 0.0164\n",
      "Epoch 142: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.0932e-04 - mae: 0.0178\n",
      "Epoch 143/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 9.8318e-04 - mae: 0.0205\n",
      "Epoch 143: loss did not improve from 0.00091\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0010 - mae: 0.0209\n",
      "Epoch 144/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.1586e-04 - mae: 0.0142\n",
      "Epoch 144: loss improved from 0.00091 to 0.00089, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.8568e-04 - mae: 0.0177\n",
      "Epoch 145/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.8231e-04 - mae: 0.0188\n",
      "Epoch 145: loss did not improve from 0.00089\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.5532e-04 - mae: 0.0201\n",
      "Epoch 146/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.9562e-04 - mae: 0.0163\n",
      "Epoch 146: loss improved from 0.00089 to 0.00087, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.7236e-04 - mae: 0.0177\n",
      "Epoch 147/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.5335e-04 - mae: 0.0183\n",
      "Epoch 147: loss did not improve from 0.00087\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.2800e-04 - mae: 0.0196\n",
      "Epoch 148/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.9020e-04 - mae: 0.0163\n",
      "Epoch 148: loss improved from 0.00087 to 0.00087, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.6666e-04 - mae: 0.0177\n",
      "Epoch 149/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.4101e-04 - mae: 0.0181\n",
      "Epoch 149: loss did not improve from 0.00087\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.1651e-04 - mae: 0.0194\n",
      "Epoch 150/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.0156e-04 - mae: 0.0143\n",
      "Epoch 150: loss improved from 0.00087 to 0.00086, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.6353e-04 - mae: 0.0177\n",
      "Epoch 151/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.4011e-04 - mae: 0.0162\n",
      "Epoch 151: loss did not improve from 0.00086\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.1142e-04 - mae: 0.0193\n",
      "Epoch 152/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.8544e-04 - mae: 0.0163\n",
      "Epoch 152: loss improved from 0.00086 to 0.00086, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.6132e-04 - mae: 0.0177\n",
      "Epoch 153/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.3456e-04 - mae: 0.0180\n",
      "Epoch 153: loss did not improve from 0.00086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 17ms/step - loss: 9.1070e-04 - mae: 0.0193\n",
      "Epoch 154/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.8401e-04 - mae: 0.0163\n",
      "Epoch 154: loss improved from 0.00086 to 0.00086, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.5945e-04 - mae: 0.0177\n",
      "Epoch 155/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.3508e-04 - mae: 0.0180\n",
      "Epoch 155: loss did not improve from 0.00086\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.1129e-04 - mae: 0.0194\n",
      "Epoch 156/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.8282e-04 - mae: 0.0162\n",
      "Epoch 156: loss improved from 0.00086 to 0.00086, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.5776e-04 - mae: 0.0176\n",
      "Epoch 157/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.3671e-04 - mae: 0.0181\n",
      "Epoch 157: loss did not improve from 0.00086\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.1291e-04 - mae: 0.0194\n",
      "Epoch 158/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.8199e-04 - mae: 0.0161\n",
      "Epoch 158: loss improved from 0.00086 to 0.00086, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.5636e-04 - mae: 0.0175\n",
      "Epoch 159/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.3743e-04 - mae: 0.0181\n",
      "Epoch 159: loss did not improve from 0.00086\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.1363e-04 - mae: 0.0194\n",
      "Epoch 160/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.8053e-04 - mae: 0.0161\n",
      "Epoch 160: loss improved from 0.00086 to 0.00085, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.5437e-04 - mae: 0.0175\n",
      "Epoch 161/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.3642e-04 - mae: 0.0181\n",
      "Epoch 161: loss did not improve from 0.00085\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.1262e-04 - mae: 0.0194\n",
      "Epoch 162/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.7851e-04 - mae: 0.0160\n",
      "Epoch 162: loss improved from 0.00085 to 0.00085, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.5187e-04 - mae: 0.0174\n",
      "Epoch 163/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.3418e-04 - mae: 0.0180\n",
      "Epoch 163: loss did not improve from 0.00085\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 9.1041e-04 - mae: 0.0194\n",
      "Epoch 164/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.7602e-04 - mae: 0.0160\n",
      "Epoch 164: loss improved from 0.00085 to 0.00085, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.4896e-04 - mae: 0.0174\n",
      "Epoch 165/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.3028e-04 - mae: 0.0180\n",
      "Epoch 165: loss did not improve from 0.00085\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 9.0663e-04 - mae: 0.0193\n",
      "Epoch 166/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.7326e-04 - mae: 0.0159\n",
      "Epoch 166: loss improved from 0.00085 to 0.00085, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.4586e-04 - mae: 0.0173\n",
      "Epoch 167/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.2679e-04 - mae: 0.0179\n",
      "Epoch 167: loss did not improve from 0.00085\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 9.0319e-04 - mae: 0.0193\n",
      "Epoch 168/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.7067e-04 - mae: 0.0159\n",
      "Epoch 168: loss improved from 0.00085 to 0.00084, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.4292e-04 - mae: 0.0173\n",
      "Epoch 169/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.2209e-04 - mae: 0.0178\n",
      "Epoch 169: loss did not improve from 0.00084\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.9866e-04 - mae: 0.0192\n",
      "Epoch 170/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.6803e-04 - mae: 0.0159\n",
      "Epoch 170: loss improved from 0.00084 to 0.00084, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.3998e-04 - mae: 0.0172\n",
      "Epoch 171/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.1804e-04 - mae: 0.0178\n",
      "Epoch 171: loss did not improve from 0.00084\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.9469e-04 - mae: 0.0191\n",
      "Epoch 172/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.6546e-04 - mae: 0.0158\n",
      "Epoch 172: loss improved from 0.00084 to 0.00084, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.3714e-04 - mae: 0.0172\n",
      "Epoch 173/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.1450e-04 - mae: 0.0177\n",
      "Epoch 173: loss did not improve from 0.00084\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.9126e-04 - mae: 0.0191\n",
      "Epoch 174/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.6332e-04 - mae: 0.0158\n",
      "Epoch 174: loss improved from 0.00084 to 0.00083, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.3469e-04 - mae: 0.0172\n",
      "Epoch 175/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.1185e-04 - mae: 0.0177\n",
      "Epoch 175: loss did not improve from 0.00083\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.8872e-04 - mae: 0.0191\n",
      "Epoch 176/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.6154e-04 - mae: 0.0157\n",
      "Epoch 176: loss improved from 0.00083 to 0.00083, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.3258e-04 - mae: 0.0171\n",
      "Epoch 177/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.1265e-04 - mae: 0.0159\n",
      "Epoch 177: loss did not improve from 0.00083\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.8688e-04 - mae: 0.0190\n",
      "Epoch 178/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.6024e-04 - mae: 0.0157\n",
      "Epoch 178: loss improved from 0.00083 to 0.00083, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.3091e-04 - mae: 0.0171\n",
      "Epoch 179/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.0872e-04 - mae: 0.0177\n",
      "Epoch 179: loss did not improve from 0.00083\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.8569e-04 - mae: 0.0190\n",
      "Epoch 180/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.5846e-04 - mae: 0.0157\n",
      "Epoch 180: loss improved from 0.00083 to 0.00083, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.2879e-04 - mae: 0.0170\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.8356e-04 - mae: 0.0190\n",
      "Epoch 181: loss did not improve from 0.00083\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.8356e-04 - mae: 0.0190\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.2676e-04 - mae: 0.0170\n",
      "Epoch 182: loss improved from 0.00083 to 0.00083, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 8.2676e-04 - mae: 0.0170\n",
      "Epoch 183/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 8.0479e-04 - mae: 0.0177\n",
      "Epoch 183: loss did not improve from 0.00083\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.8195e-04 - mae: 0.0190\n",
      "Epoch 184/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.6230e-04 - mae: 0.0135\n",
      "Epoch 184: loss improved from 0.00083 to 0.00083, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.2507e-04 - mae: 0.0170\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.8105e-04 - mae: 0.0190\n",
      "Epoch 185: loss did not improve from 0.00083\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.8105e-04 - mae: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.5375e-04 - mae: 0.0155\n",
      "Epoch 186: loss improved from 0.00083 to 0.00082, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.2310e-04 - mae: 0.0169\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.7941e-04 - mae: 0.0190\n",
      "Epoch 187: loss did not improve from 0.00082\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.7941e-04 - mae: 0.0190\n",
      "Epoch 188/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.0582e-04 - mae: 0.0165\n",
      "Epoch 188: loss improved from 0.00082 to 0.00082, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.2118e-04 - mae: 0.0169\n",
      "Epoch 189/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.5975e-04 - mae: 0.0186\n",
      "Epoch 189: loss did not improve from 0.00082\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.7770e-04 - mae: 0.0190\n",
      "Epoch 190/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.0422e-04 - mae: 0.0165\n",
      "Epoch 190: loss improved from 0.00082 to 0.00082, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 8.1941e-04 - mae: 0.0168\n",
      "Epoch 191/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.5852e-04 - mae: 0.0186\n",
      "Epoch 191: loss did not improve from 0.00082\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.7634e-04 - mae: 0.0189\n",
      "Epoch 192/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.0263e-04 - mae: 0.0164\n",
      "Epoch 192: loss improved from 0.00082 to 0.00082, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.1764e-04 - mae: 0.0168\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.7453e-04 - mae: 0.0189\n",
      "Epoch 193: loss did not improve from 0.00082\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.7453e-04 - mae: 0.0189\n",
      "Epoch 194/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.0098e-04 - mae: 0.0164\n",
      "Epoch 194: loss improved from 0.00082 to 0.00082, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.1581e-04 - mae: 0.0168\n",
      "Epoch 195/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.5532e-04 - mae: 0.0186\n",
      "Epoch 195: loss did not improve from 0.00082\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.7287e-04 - mae: 0.0189\n",
      "Epoch 196/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.9924e-04 - mae: 0.0163\n",
      "Epoch 196: loss improved from 0.00082 to 0.00081, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.1391e-04 - mae: 0.0167\n",
      "Epoch 197/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.9328e-04 - mae: 0.0175\n",
      "Epoch 197: loss did not improve from 0.00081\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 8.7079e-04 - mae: 0.0189\n",
      "Epoch 198/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.9731e-04 - mae: 0.0163\n",
      "Epoch 198: loss improved from 0.00081 to 0.00081, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.1182e-04 - mae: 0.0167\n",
      "Epoch 199/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.9267e-04 - mae: 0.0157\n",
      "Epoch 199: loss did not improve from 0.00081\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.6845e-04 - mae: 0.0188\n",
      "Epoch 200/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.4235e-04 - mae: 0.0153\n",
      "Epoch 200: loss improved from 0.00081 to 0.00081, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.0957e-04 - mae: 0.0166\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.6586e-04 - mae: 0.0188\n",
      "Epoch 201: loss did not improve from 0.00081\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 8.6586e-04 - mae: 0.0188\n",
      "Epoch 202/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.9306e-04 - mae: 0.0162\n",
      "Epoch 202: loss improved from 0.00081 to 0.00081, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.0730e-04 - mae: 0.0166\n",
      "Epoch 203/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.4609e-04 - mae: 0.0184\n",
      "Epoch 203: loss did not improve from 0.00081\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 8.6313e-04 - mae: 0.0188\n",
      "Epoch 204/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.9093e-04 - mae: 0.0162\n",
      "Epoch 204: loss improved from 0.00081 to 0.00081, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.0503e-04 - mae: 0.0166\n",
      "Epoch 205/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.4342e-04 - mae: 0.0184\n",
      "Epoch 205: loss did not improve from 0.00081\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.6035e-04 - mae: 0.0187\n",
      "Epoch 206/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.8889e-04 - mae: 0.0162\n",
      "Epoch 206: loss improved from 0.00081 to 0.00080, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 8.0285e-04 - mae: 0.0165\n",
      "Epoch 207/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.4109e-04 - mae: 0.0184\n",
      "Epoch 207: loss did not improve from 0.00080\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.5791e-04 - mae: 0.0187\n",
      "Epoch 208/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.8715e-04 - mae: 0.0161\n",
      "Epoch 208: loss improved from 0.00080 to 0.00080, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 8.0097e-04 - mae: 0.0165\n",
      "Epoch 209/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.3889e-04 - mae: 0.0183\n",
      "Epoch 209: loss did not improve from 0.00080\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.5562e-04 - mae: 0.0187\n",
      "Epoch 210/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.8552e-04 - mae: 0.0161\n",
      "Epoch 210: loss improved from 0.00080 to 0.00080, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 7.9919e-04 - mae: 0.0165\n",
      "Epoch 211/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.3748e-04 - mae: 0.0183\n",
      "Epoch 211: loss did not improve from 0.00080\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.5410e-04 - mae: 0.0187\n",
      "Epoch 212/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.8406e-04 - mae: 0.0161\n",
      "Epoch 212: loss improved from 0.00080 to 0.00080, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 7.9759e-04 - mae: 0.0164\n",
      "Epoch 213/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 8.3586e-04 - mae: 0.0183\n",
      "Epoch 213: loss did not improve from 0.00080\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 8.5238e-04 - mae: 0.0186\n",
      "Epoch 214/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.8259e-04 - mae: 0.0160\n",
      "Epoch 214: loss improved from 0.00080 to 0.00080, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 7.9597e-04 - mae: 0.0164\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.5073e-04 - mae: 0.0186\n",
      "Epoch 215: loss did not improve from 0.00080\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.5073e-04 - mae: 0.0186\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.9415e-04 - mae: 0.0164\n",
      "Epoch 216: loss improved from 0.00080 to 0.00079, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 7.9415e-04 - mae: 0.0164\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.4877e-04 - mae: 0.0186\n",
      "Epoch 217: loss did not improve from 0.00079\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 8.4877e-04 - mae: 0.0186\n",
      "Epoch 218/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.7897e-04 - mae: 0.0160\n",
      "Epoch 218: loss improved from 0.00079 to 0.00079, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.9212e-04 - mae: 0.0163\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.4641e-04 - mae: 0.0186\n",
      "Epoch 219: loss did not improve from 0.00079\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.4641e-04 - mae: 0.0186\n",
      "Epoch 220/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.7685e-04 - mae: 0.0159\n",
      "Epoch 220: loss improved from 0.00079 to 0.00079, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 7.8989e-04 - mae: 0.0163\n",
      "Epoch 221/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.6629e-04 - mae: 0.0172\n",
      "Epoch 221: loss did not improve from 0.00079\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.4358e-04 - mae: 0.0185\n",
      "Epoch 222/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.7460e-04 - mae: 0.0159\n",
      "Epoch 222: loss improved from 0.00079 to 0.00079, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 7.8753e-04 - mae: 0.0163\n",
      "Epoch 223/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.6340e-04 - mae: 0.0171\n",
      "Epoch 223: loss did not improve from 0.00079\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.4061e-04 - mae: 0.0185\n",
      "Epoch 224/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.2096e-04 - mae: 0.0149\n",
      "Epoch 224: loss improved from 0.00079 to 0.00079, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 21ms/step - loss: 7.8514e-04 - mae: 0.0162\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.3788e-04 - mae: 0.0185\n",
      "Epoch 225: loss did not improve from 0.00079\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 8.3788e-04 - mae: 0.0185\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.8271e-04 - mae: 0.0162\n",
      "Epoch 226: loss improved from 0.00079 to 0.00078, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 7.8271e-04 - mae: 0.0162\n",
      "Epoch 227/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.5798e-04 - mae: 0.0171\n",
      "Epoch 227: loss did not improve from 0.00078\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.3497e-04 - mae: 0.0184\n",
      "Epoch 228/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.6764e-04 - mae: 0.0158\n",
      "Epoch 228: loss improved from 0.00078 to 0.00078, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 7.8029e-04 - mae: 0.0162\n",
      "Epoch 229/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.5507e-04 - mae: 0.0170\n",
      "Epoch 229: loss did not improve from 0.00078\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.3198e-04 - mae: 0.0184\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.7813e-04 - mae: 0.0161\n",
      "Epoch 230: loss improved from 0.00078 to 0.00078, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 7.7813e-04 - mae: 0.0161\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.2963e-04 - mae: 0.0183\n",
      "Epoch 231: loss did not improve from 0.00078\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.2963e-04 - mae: 0.0183\n",
      "Epoch 232/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.6361e-04 - mae: 0.0157\n",
      "Epoch 232: loss improved from 0.00078 to 0.00078, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.7606e-04 - mae: 0.0161\n",
      "Epoch 233/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.5776e-04 - mae: 0.0152\n",
      "Epoch 233: loss did not improve from 0.00078\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.2734e-04 - mae: 0.0183\n",
      "Epoch 234/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.6177e-04 - mae: 0.0157\n",
      "Epoch 234: loss improved from 0.00078 to 0.00077, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.7412e-04 - mae: 0.0161\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.2546e-04 - mae: 0.0183\n",
      "Epoch 235: loss did not improve from 0.00077\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.2546e-04 - mae: 0.0183\n",
      "Epoch 236/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.5998e-04 - mae: 0.0157\n",
      "Epoch 236: loss improved from 0.00077 to 0.00077, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.7223e-04 - mae: 0.0160\n",
      "Epoch 237/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.5462e-04 - mae: 0.0151\n",
      "Epoch 237: loss did not improve from 0.00077\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.2360e-04 - mae: 0.0183\n",
      "Epoch 238/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.5803e-04 - mae: 0.0156\n",
      "Epoch 238: loss improved from 0.00077 to 0.00077, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 7.7020e-04 - mae: 0.0160\n",
      "Epoch 239/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.4515e-04 - mae: 0.0169\n",
      "Epoch 239: loss did not improve from 0.00077\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.2155e-04 - mae: 0.0182\n",
      "Epoch 240/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.5657e-04 - mae: 0.0156\n",
      "Epoch 240: loss improved from 0.00077 to 0.00077, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.6864e-04 - mae: 0.0160\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.1971e-04 - mae: 0.0182\n",
      "Epoch 241: loss did not improve from 0.00077\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.1971e-04 - mae: 0.0182\n",
      "Epoch 242/500\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 2.7283e-04 - mae: 0.0100\n",
      "Epoch 242: loss improved from 0.00077 to 0.00077, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 7.6669e-04 - mae: 0.0159\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 8.1775e-04 - mae: 0.0182\n",
      "Epoch 243: loss did not improve from 0.00077\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 8.1775e-04 - mae: 0.0182\n",
      "Epoch 244/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.1101e-04 - mae: 0.0124\n",
      "Epoch 244: loss improved from 0.00077 to 0.00076, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.6460e-04 - mae: 0.0159\n",
      "Epoch 245/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.3960e-04 - mae: 0.0168\n",
      "Epoch 245: loss did not improve from 0.00076\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 8.1557e-04 - mae: 0.0182\n",
      "Epoch 246/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.0095e-04 - mae: 0.0146\n",
      "Epoch 246: loss improved from 0.00076 to 0.00076, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.6255e-04 - mae: 0.0159\n",
      "Epoch 247/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.4602e-04 - mae: 0.0150\n",
      "Epoch 247: loss did not improve from 0.00076\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.1311e-04 - mae: 0.0181\n",
      "Epoch 248/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.9890e-04 - mae: 0.0145\n",
      "Epoch 248: loss improved from 0.00076 to 0.00076, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.6028e-04 - mae: 0.0159\n",
      "Epoch 249/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.4391e-04 - mae: 0.0150\n",
      "Epoch 249: loss did not improve from 0.00076\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.1038e-04 - mae: 0.0181\n",
      "Epoch 250/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/23 [=========================>....] - ETA: 0s - loss: 5.0608e-04 - mae: 0.0123\n",
      "Epoch 250: loss improved from 0.00076 to 0.00076, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.5794e-04 - mae: 0.0158\n",
      "Epoch 251/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.3225e-04 - mae: 0.0167\n",
      "Epoch 251: loss did not improve from 0.00076\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.0773e-04 - mae: 0.0180\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.5553e-04 - mae: 0.0158\n",
      "Epoch 252: loss improved from 0.00076 to 0.00076, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.5553e-04 - mae: 0.0158\n",
      "Epoch 253/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.3975e-04 - mae: 0.0149\n",
      "Epoch 253: loss did not improve from 0.00076\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.0485e-04 - mae: 0.0180\n",
      "Epoch 254/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.0271e-04 - mae: 0.0123\n",
      "Epoch 254: loss improved from 0.00076 to 0.00075, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.5335e-04 - mae: 0.0158\n",
      "Epoch 255/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.3779e-04 - mae: 0.0149\n",
      "Epoch 255: loss did not improve from 0.00075\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.0220e-04 - mae: 0.0180\n",
      "Epoch 256/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.4039e-04 - mae: 0.0154\n",
      "Epoch 256: loss improved from 0.00075 to 0.00075, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.5183e-04 - mae: 0.0157\n",
      "Epoch 257/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.2598e-04 - mae: 0.0166\n",
      "Epoch 257: loss did not improve from 0.00075\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 8.0091e-04 - mae: 0.0180\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.5038e-04 - mae: 0.0157\n",
      "Epoch 258: loss improved from 0.00075 to 0.00075, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.5038e-04 - mae: 0.0157\n",
      "Epoch 259/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.2488e-04 - mae: 0.0166\n",
      "Epoch 259: loss did not improve from 0.00075\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.9966e-04 - mae: 0.0179\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.4887e-04 - mae: 0.0157\n",
      "Epoch 260: loss improved from 0.00075 to 0.00075, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 7.4887e-04 - mae: 0.0157\n",
      "Epoch 261/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.8397e-04 - mae: 0.0176\n",
      "Epoch 261: loss did not improve from 0.00075\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.9820e-04 - mae: 0.0179\n",
      "Epoch 262/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.3601e-04 - mae: 0.0153\n",
      "Epoch 262: loss improved from 0.00075 to 0.00075, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.4721e-04 - mae: 0.0157\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.9622e-04 - mae: 0.0179\n",
      "Epoch 263: loss did not improve from 0.00075\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.9622e-04 - mae: 0.0179\n",
      "Epoch 264/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.8622e-04 - mae: 0.0143\n",
      "Epoch 264: loss improved from 0.00075 to 0.00075, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.4553e-04 - mae: 0.0156\n",
      "Epoch 265/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.2027e-04 - mae: 0.0166\n",
      "Epoch 265: loss did not improve from 0.00075\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.9463e-04 - mae: 0.0179\n",
      "Epoch 266/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.3263e-04 - mae: 0.0153\n",
      "Epoch 266: loss improved from 0.00075 to 0.00074, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 7.4369e-04 - mae: 0.0156\n",
      "Epoch 267/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.7810e-04 - mae: 0.0175\n",
      "Epoch 267: loss did not improve from 0.00074\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.9211e-04 - mae: 0.0178\n",
      "Epoch 268/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.3097e-04 - mae: 0.0152\n",
      "Epoch 268: loss improved from 0.00074 to 0.00074, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 7.4196e-04 - mae: 0.0156\n",
      "Epoch 269/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.7611e-04 - mae: 0.0175\n",
      "Epoch 269: loss did not improve from 0.00074\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 7.8999e-04 - mae: 0.0178\n",
      "Epoch 270/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.2921e-04 - mae: 0.0152\n",
      "Epoch 270: loss improved from 0.00074 to 0.00074, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.4013e-04 - mae: 0.0156\n",
      "Epoch 271/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.7408e-04 - mae: 0.0175\n",
      "Epoch 271: loss did not improve from 0.00074\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.8786e-04 - mae: 0.0178\n",
      "Epoch 272/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.2757e-04 - mae: 0.0152\n",
      "Epoch 272: loss improved from 0.00074 to 0.00074, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.3842e-04 - mae: 0.0155\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.8588e-04 - mae: 0.0178\n",
      "Epoch 273: loss did not improve from 0.00074\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.8588e-04 - mae: 0.0178\n",
      "Epoch 274/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.7818e-04 - mae: 0.0142\n",
      "Epoch 274: loss improved from 0.00074 to 0.00074, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.3620e-04 - mae: 0.0155\n",
      "Epoch 275/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 5.2205e-04 - mae: 0.0147\n",
      "Epoch 275: loss did not improve from 0.00074\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.8314e-04 - mae: 0.0177\n",
      "Epoch 276/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.2271e-04 - mae: 0.0151\n",
      "Epoch 276: loss improved from 0.00074 to 0.00073, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 7.3347e-04 - mae: 0.0155\n",
      "Epoch 277/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.0634e-04 - mae: 0.0164\n",
      "Epoch 277: loss did not improve from 0.00073\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.7952e-04 - mae: 0.0177\n",
      "Epoch 278/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.8603e-04 - mae: 0.0120\n",
      "Epoch 278: loss improved from 0.00073 to 0.00073, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.3025e-04 - mae: 0.0154\n",
      "Epoch 279/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 7.0237e-04 - mae: 0.0163\n",
      "Epoch 279: loss did not improve from 0.00073\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.7527e-04 - mae: 0.0176\n",
      "Epoch 280/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.6999e-04 - mae: 0.0141\n",
      "Epoch 280: loss improved from 0.00073 to 0.00073, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.2756e-04 - mae: 0.0154\n",
      "Epoch 281/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.9948e-04 - mae: 0.0162\n",
      "Epoch 281: loss did not improve from 0.00073\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.7220e-04 - mae: 0.0176\n",
      "Epoch 282/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.8243e-04 - mae: 0.0119\n",
      "Epoch 282: loss improved from 0.00073 to 0.00073, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.2512e-04 - mae: 0.0154\n",
      "Epoch 283/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.9686e-04 - mae: 0.0162\n",
      "Epoch 283: loss did not improve from 0.00073\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.6940e-04 - mae: 0.0175\n",
      "Epoch 284/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.6566e-04 - mae: 0.0141\n",
      "Epoch 284: loss improved from 0.00073 to 0.00072, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.2283e-04 - mae: 0.0153\n",
      "Epoch 285/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.9457e-04 - mae: 0.0162\n",
      "Epoch 285: loss did not improve from 0.00072\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.6693e-04 - mae: 0.0175\n",
      "Epoch 286/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.7933e-04 - mae: 0.0119\n",
      "Epoch 286: loss improved from 0.00072 to 0.00072, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.2073e-04 - mae: 0.0153\n",
      "Epoch 287/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.9249e-04 - mae: 0.0161\n",
      "Epoch 287: loss did not improve from 0.00072\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.6465e-04 - mae: 0.0174\n",
      "Epoch 288/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.6210e-04 - mae: 0.0140\n",
      "Epoch 288: loss improved from 0.00072 to 0.00072, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.1880e-04 - mae: 0.0153\n",
      "Epoch 289/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.9068e-04 - mae: 0.0161\n",
      "Epoch 289: loss did not improve from 0.00072\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.6265e-04 - mae: 0.0174\n",
      "Epoch 290/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.6050e-04 - mae: 0.0140\n",
      "Epoch 290: loss improved from 0.00072 to 0.00072, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.1695e-04 - mae: 0.0153\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.6078e-04 - mae: 0.0174\n",
      "Epoch 291: loss did not improve from 0.00072\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.6078e-04 - mae: 0.0174\n",
      "Epoch 292/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.7544e-04 - mae: 0.0118\n",
      "Epoch 292: loss improved from 0.00072 to 0.00072, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.1516e-04 - mae: 0.0152\n",
      "Epoch 293/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 7.4600e-04 - mae: 0.0171\n",
      "Epoch 293: loss did not improve from 0.00072\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 7.5890e-04 - mae: 0.0174\n",
      "Epoch 294/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.5743e-04 - mae: 0.0140\n",
      "Epoch 294: loss improved from 0.00072 to 0.00071, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.1337e-04 - mae: 0.0152\n",
      "Epoch 295/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.8561e-04 - mae: 0.0161\n",
      "Epoch 295: loss did not improve from 0.00071\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.5696e-04 - mae: 0.0173\n",
      "Epoch 296/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.7288e-04 - mae: 0.0118\n",
      "Epoch 296: loss improved from 0.00071 to 0.00071, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.1142e-04 - mae: 0.0152\n",
      "Epoch 297/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.8366e-04 - mae: 0.0160\n",
      "Epoch 297: loss did not improve from 0.00071\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.5478e-04 - mae: 0.0173\n",
      "Epoch 298/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.5389e-04 - mae: 0.0139\n",
      "Epoch 298: loss improved from 0.00071 to 0.00071, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.0936e-04 - mae: 0.0152\n",
      "Epoch 299/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.8160e-04 - mae: 0.0160\n",
      "Epoch 299: loss did not improve from 0.00071\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.5251e-04 - mae: 0.0173\n",
      "Epoch 300/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.5197e-04 - mae: 0.0139\n",
      "Epoch 300: loss improved from 0.00071 to 0.00071, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.0723e-04 - mae: 0.0152\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.5012e-04 - mae: 0.0173\n",
      "Epoch 301: loss did not improve from 0.00071\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.5012e-04 - mae: 0.0173\n",
      "Epoch 302/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.5003e-04 - mae: 0.0139\n",
      "Epoch 302: loss improved from 0.00071 to 0.00071, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.0507e-04 - mae: 0.0151\n",
      "Epoch 303/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.7731e-04 - mae: 0.0159\n",
      "Epoch 303: loss did not improve from 0.00071\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.4776e-04 - mae: 0.0172\n",
      "Epoch 304/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.4801e-04 - mae: 0.0138\n",
      "Epoch 304: loss improved from 0.00071 to 0.00070, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.0285e-04 - mae: 0.0151\n",
      "Epoch 305/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.7502e-04 - mae: 0.0159\n",
      "Epoch 305: loss did not improve from 0.00070\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.4526e-04 - mae: 0.0172\n",
      "Epoch 306/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.4604e-04 - mae: 0.0138\n",
      "Epoch 306: loss improved from 0.00070 to 0.00070, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.0066e-04 - mae: 0.0151\n",
      "Epoch 307/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.7266e-04 - mae: 0.0159\n",
      "Epoch 307: loss did not improve from 0.00070\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.4266e-04 - mae: 0.0171\n",
      "Epoch 308/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.6411e-04 - mae: 0.0116\n",
      "Epoch 308: loss improved from 0.00070 to 0.00070, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.9843e-04 - mae: 0.0150\n",
      "Epoch 309/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.9046e-04 - mae: 0.0141\n",
      "Epoch 309: loss did not improve from 0.00070\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.4000e-04 - mae: 0.0171\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 6.9613e-04 - mae: 0.0150\n",
      "Epoch 310: loss improved from 0.00070 to 0.00070, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.9613e-04 - mae: 0.0150\n",
      "Epoch 311/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.6788e-04 - mae: 0.0158\n",
      "Epoch 311: loss did not improve from 0.00070\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.3743e-04 - mae: 0.0171\n",
      "Epoch 312/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.6105e-04 - mae: 0.0116\n",
      "Epoch 312: loss improved from 0.00070 to 0.00069, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.9390e-04 - mae: 0.0150\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.3495e-04 - mae: 0.0170\n",
      "Epoch 313: loss did not improve from 0.00069\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 7.3495e-04 - mae: 0.0170\n",
      "Epoch 314/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/23 [===========================>..] - ETA: 0s - loss: 6.8190e-04 - mae: 0.0146\n",
      "Epoch 314: loss improved from 0.00069 to 0.00069, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.9184e-04 - mae: 0.0150\n",
      "Epoch 315/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.6364e-04 - mae: 0.0157\n",
      "Epoch 315: loss did not improve from 0.00069\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 7.3276e-04 - mae: 0.0170\n",
      "Epoch 316/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.3636e-04 - mae: 0.0137\n",
      "Epoch 316: loss improved from 0.00069 to 0.00069, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.8994e-04 - mae: 0.0149\n",
      "Epoch 317/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.8365e-04 - mae: 0.0140\n",
      "Epoch 317: loss did not improve from 0.00069\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.3077e-04 - mae: 0.0170\n",
      "Epoch 318/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.5708e-04 - mae: 0.0115\n",
      "Epoch 318: loss improved from 0.00069 to 0.00069, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.8802e-04 - mae: 0.0149\n",
      "Epoch 319/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.8211e-04 - mae: 0.0140\n",
      "Epoch 319: loss did not improve from 0.00069\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 7.2864e-04 - mae: 0.0169\n",
      "Epoch 320/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.5574e-04 - mae: 0.0115\n",
      "Epoch 320: loss improved from 0.00069 to 0.00069, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.8604e-04 - mae: 0.0149\n",
      "Epoch 321/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.5793e-04 - mae: 0.0156\n",
      "Epoch 321: loss did not improve from 0.00069\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 7.2642e-04 - mae: 0.0169\n",
      "Epoch 322/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.7422e-04 - mae: 0.0145\n",
      "Epoch 322: loss improved from 0.00069 to 0.00068, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.8405e-04 - mae: 0.0149\n",
      "Epoch 323/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.5597e-04 - mae: 0.0156\n",
      "Epoch 323: loss did not improve from 0.00068\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 7.2420e-04 - mae: 0.0169\n",
      "Epoch 324/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.2910e-04 - mae: 0.0136\n",
      "Epoch 324: loss improved from 0.00068 to 0.00068, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.8183e-04 - mae: 0.0149\n",
      "Epoch 325/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.5377e-04 - mae: 0.0156\n",
      "Epoch 325: loss did not improve from 0.00068\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.2175e-04 - mae: 0.0169\n",
      "Epoch 326/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.2679e-04 - mae: 0.0136\n",
      "Epoch 326: loss improved from 0.00068 to 0.00068, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.7936e-04 - mae: 0.0148\n",
      "Epoch 327/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.5137e-04 - mae: 0.0156\n",
      "Epoch 327: loss did not improve from 0.00068\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 7.1912e-04 - mae: 0.0168\n",
      "Epoch 328/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.2471e-04 - mae: 0.0136\n",
      "Epoch 328: loss improved from 0.00068 to 0.00068, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.7709e-04 - mae: 0.0148\n",
      "Epoch 329/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.4884e-04 - mae: 0.0155\n",
      "Epoch 329: loss did not improve from 0.00068\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.1635e-04 - mae: 0.0168\n",
      "Epoch 330/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.2246e-04 - mae: 0.0136\n",
      "Epoch 330: loss improved from 0.00068 to 0.00067, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.7468e-04 - mae: 0.0148\n",
      "Epoch 331/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.4636e-04 - mae: 0.0155\n",
      "Epoch 331: loss did not improve from 0.00067\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 7.1369e-04 - mae: 0.0167\n",
      "Epoch 332/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.2013e-04 - mae: 0.0135\n",
      "Epoch 332: loss improved from 0.00067 to 0.00067, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.7218e-04 - mae: 0.0147\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.1114e-04 - mae: 0.0167\n",
      "Epoch 333: loss did not improve from 0.00067\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.1114e-04 - mae: 0.0167\n",
      "Epoch 334/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.4507e-04 - mae: 0.0114\n",
      "Epoch 334: loss improved from 0.00067 to 0.00067, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.6993e-04 - mae: 0.0147\n",
      "Epoch 335/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.4135e-04 - mae: 0.0154\n",
      "Epoch 335: loss did not improve from 0.00067\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.0825e-04 - mae: 0.0167\n",
      "Epoch 336/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.1623e-04 - mae: 0.0135\n",
      "Epoch 336: loss improved from 0.00067 to 0.00067, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.6790e-04 - mae: 0.0147\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 7.0590e-04 - mae: 0.0166\n",
      "Epoch 337: loss did not improve from 0.00067\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.0590e-04 - mae: 0.0166\n",
      "Epoch 338/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.4237e-04 - mae: 0.0113\n",
      "Epoch 338: loss improved from 0.00067 to 0.00067, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.6570e-04 - mae: 0.0147\n",
      "Epoch 339/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.3675e-04 - mae: 0.0153\n",
      "Epoch 339: loss did not improve from 0.00067\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 7.0316e-04 - mae: 0.0166\n",
      "Epoch 340/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.4079e-04 - mae: 0.0113\n",
      "Epoch 340: loss improved from 0.00067 to 0.00066, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.6323e-04 - mae: 0.0147\n",
      "Epoch 341/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.3404e-04 - mae: 0.0153\n",
      "Epoch 341: loss did not improve from 0.00066\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 7.0024e-04 - mae: 0.0165\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 6.6073e-04 - mae: 0.0146\n",
      "Epoch 342: loss improved from 0.00066 to 0.00066, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 6.6073e-04 - mae: 0.0146\n",
      "Epoch 343/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.8577e-04 - mae: 0.0162\n",
      "Epoch 343: loss did not improve from 0.00066\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.9726e-04 - mae: 0.0165\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 6.5842e-04 - mae: 0.0146\n",
      "Epoch 344: loss improved from 0.00066 to 0.00066, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 6.5842e-04 - mae: 0.0146\n",
      "Epoch 345/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.2908e-04 - mae: 0.0152\n",
      "Epoch 345: loss did not improve from 0.00066\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 6.9484e-04 - mae: 0.0165\n",
      "Epoch 346/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.4621e-04 - mae: 0.0142\n",
      "Epoch 346: loss improved from 0.00066 to 0.00066, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 6.5590e-04 - mae: 0.0146\n",
      "Epoch 347/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.8045e-04 - mae: 0.0161\n",
      "Epoch 347: loss did not improve from 0.00066\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 6.9186e-04 - mae: 0.0164\n",
      "Epoch 348/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.4414e-04 - mae: 0.0142\n",
      "Epoch 348: loss improved from 0.00066 to 0.00065, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 6.5381e-04 - mae: 0.0146\n",
      "Epoch 349/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.7821e-04 - mae: 0.0161\n",
      "Epoch 349: loss did not improve from 0.00065\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 6.8959e-04 - mae: 0.0164\n",
      "Epoch 350/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.4221e-04 - mae: 0.0142\n",
      "Epoch 350: loss improved from 0.00065 to 0.00065, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 6.5186e-04 - mae: 0.0145\n",
      "Epoch 351/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.7631e-04 - mae: 0.0161\n",
      "Epoch 351: loss did not improve from 0.00065\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 6.8763e-04 - mae: 0.0164\n",
      "Epoch 352/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.4010e-04 - mae: 0.0142\n",
      "Epoch 352: loss improved from 0.00065 to 0.00065, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 6.4974e-04 - mae: 0.0145\n",
      "Epoch 353/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.7383e-04 - mae: 0.0160\n",
      "Epoch 353: loss did not improve from 0.00065\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 6.8511e-04 - mae: 0.0163\n",
      "Epoch 354/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.3819e-04 - mae: 0.0141\n",
      "Epoch 354: loss improved from 0.00065 to 0.00065, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 6.4781e-04 - mae: 0.0145\n",
      "Epoch 355/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.7173e-04 - mae: 0.0160\n",
      "Epoch 355: loss did not improve from 0.00065\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 6.8298e-04 - mae: 0.0163\n",
      "Epoch 356/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.3598e-04 - mae: 0.0141\n",
      "Epoch 356: loss improved from 0.00065 to 0.00065, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 6.4559e-04 - mae: 0.0145\n",
      "Epoch 357/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.4785e-04 - mae: 0.0134\n",
      "Epoch 357: loss did not improve from 0.00065\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 6.8045e-04 - mae: 0.0163\n",
      "Epoch 358/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.3321e-04 - mae: 0.0141\n",
      "Epoch 358: loss improved from 0.00065 to 0.00064, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 6.4282e-04 - mae: 0.0144\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 6.7720e-04 - mae: 0.0162\n",
      "Epoch 359: loss did not improve from 0.00064\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.7720e-04 - mae: 0.0162\n",
      "Epoch 360/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.3013e-04 - mae: 0.0140\n",
      "Epoch 360: loss improved from 0.00064 to 0.00064, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 6.3974e-04 - mae: 0.0144\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 6.7399e-04 - mae: 0.0162\n",
      "Epoch 361: loss did not improve from 0.00064\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.7399e-04 - mae: 0.0162\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 6.3635e-04 - mae: 0.0144\n",
      "Epoch 362: loss improved from 0.00064 to 0.00064, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.3635e-04 - mae: 0.0144\n",
      "Epoch 363/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.4110e-04 - mae: 0.0133\n",
      "Epoch 363: loss did not improve from 0.00064\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.7045e-04 - mae: 0.0161\n",
      "Epoch 364/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.2059e-04 - mae: 0.0110\n",
      "Epoch 364: loss improved from 0.00064 to 0.00063, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.3308e-04 - mae: 0.0143\n",
      "Epoch 365/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.3934e-04 - mae: 0.0132\n",
      "Epoch 365: loss did not improve from 0.00063\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 6.6770e-04 - mae: 0.0161\n",
      "Epoch 366/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.1837e-04 - mae: 0.0110\n",
      "Epoch 366: loss improved from 0.00063 to 0.00063, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.3021e-04 - mae: 0.0143\n",
      "Epoch 367/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.0267e-04 - mae: 0.0149\n",
      "Epoch 367: loss did not improve from 0.00063\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.6615e-04 - mae: 0.0161\n",
      "Epoch 368/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 5.7797e-04 - mae: 0.0130\n",
      "Epoch 368: loss improved from 0.00063 to 0.00063, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.2740e-04 - mae: 0.0142\n",
      "Epoch 369/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 6.0059e-04 - mae: 0.0149\n",
      "Epoch 369: loss did not improve from 0.00063\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 6.6392e-04 - mae: 0.0161\n",
      "Epoch 370/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 5.7641e-04 - mae: 0.0130\n",
      "Epoch 370: loss improved from 0.00063 to 0.00063, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.2564e-04 - mae: 0.0142\n",
      "Epoch 371/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 5.9957e-04 - mae: 0.0149\n",
      "Epoch 371: loss did not improve from 0.00063\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 6.6275e-04 - mae: 0.0161\n",
      "Epoch 372/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 5.7562e-04 - mae: 0.0130\n",
      "Epoch 372: loss improved from 0.00063 to 0.00062, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.2460e-04 - mae: 0.0142\n",
      "Epoch 373/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.3612e-04 - mae: 0.0133\n",
      "Epoch 373: loss did not improve from 0.00062\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 6.6241e-04 - mae: 0.0161\n",
      "Epoch 374/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.1381e-04 - mae: 0.0109\n",
      "Epoch 374: loss improved from 0.00062 to 0.00062, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.2356e-04 - mae: 0.0142\n",
      "Epoch 375/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 5.9881e-04 - mae: 0.0149\n",
      "Epoch 375: loss did not improve from 0.00062\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.6159e-04 - mae: 0.0161\n",
      "Epoch 376/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.1288e-04 - mae: 0.0109\n",
      "Epoch 376: loss improved from 0.00062 to 0.00062, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.2197e-04 - mae: 0.0141\n",
      "Epoch 377/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.3453e-04 - mae: 0.0133\n",
      "Epoch 377: loss did not improve from 0.00062\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.5969e-04 - mae: 0.0161\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/23 [==========================>...] - ETA: 0s - loss: 5.7059e-04 - mae: 0.0130\n",
      "Epoch 378: loss improved from 0.00062 to 0.00062, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.1904e-04 - mae: 0.0141\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 6.5630e-04 - mae: 0.0161\n",
      "Epoch 379: loss did not improve from 0.00062\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 6.5630e-04 - mae: 0.0161\n",
      "Epoch 380/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.0392e-04 - mae: 0.0137\n",
      "Epoch 380: loss improved from 0.00062 to 0.00061, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 6.1353e-04 - mae: 0.0140\n",
      "Epoch 381/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.3917e-04 - mae: 0.0157\n",
      "Epoch 381: loss did not improve from 0.00061\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 6.4996e-04 - mae: 0.0160\n",
      "Epoch 382/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 5.9867e-04 - mae: 0.0136\n",
      "Epoch 382: loss improved from 0.00061 to 0.00061, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 6.0836e-04 - mae: 0.0140\n",
      "Epoch 383/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.3212e-04 - mae: 0.0156\n",
      "Epoch 383: loss did not improve from 0.00061\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 6.4292e-04 - mae: 0.0158\n",
      "Epoch 384/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 5.9443e-04 - mae: 0.0136\n",
      "Epoch 384: loss improved from 0.00061 to 0.00060, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 6.0415e-04 - mae: 0.0139\n",
      "Epoch 385/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.2701e-04 - mae: 0.0154\n",
      "Epoch 385: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 6.3782e-04 - mae: 0.0157\n",
      "Epoch 386/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 5.9145e-04 - mae: 0.0135\n",
      "Epoch 386: loss improved from 0.00060 to 0.00060, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 6.0120e-04 - mae: 0.0139\n",
      "Epoch 387/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.2401e-04 - mae: 0.0154\n",
      "Epoch 387: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 6.3480e-04 - mae: 0.0156\n",
      "Epoch 388/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 5.9037e-04 - mae: 0.0135\n",
      "Epoch 388: loss improved from 0.00060 to 0.00060, saving model to results/lstm_time_series\\model.h5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 6.0009e-04 - mae: 0.0139\n",
      "Epoch 389/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.2356e-04 - mae: 0.0154\n",
      "Epoch 389: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 6.3430e-04 - mae: 0.0156\n",
      "Epoch 390/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 3.9841e-04 - mae: 0.0107\n",
      "Epoch 390: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 6.0050e-04 - mae: 0.0139\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 6.3592e-04 - mae: 0.0157\n",
      "Epoch 391: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 6.3592e-04 - mae: 0.0157\n",
      "Epoch 392/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 5.9340e-04 - mae: 0.0136\n",
      "Epoch 392: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.0307e-04 - mae: 0.0139\n",
      "Epoch 393/500\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 6.2980e-04 - mae: 0.0155\n",
      "Epoch 393: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 6.4039e-04 - mae: 0.0158\n",
      "Epoch 394/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 5.5931e-04 - mae: 0.0128\n",
      "Epoch 394: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.0627e-04 - mae: 0.0140\n",
      "Epoch 395/500\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 4.2303e-04 - mae: 0.0131\n",
      "Epoch 395: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.4499e-04 - mae: 0.0159\n",
      "Epoch 396/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 5.6295e-04 - mae: 0.0129\n",
      "Epoch 396: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 6.0939e-04 - mae: 0.0141\n",
      "Epoch 397/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 5.8807e-04 - mae: 0.0149\n",
      "Epoch 397: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 6.4881e-04 - mae: 0.0160\n",
      "Epoch 398/500\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 5.6397e-04 - mae: 0.0129Restoring model weights from the end of the best epoch: 388.\n",
      "\n",
      "Epoch 398: loss did not improve from 0.00060\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 6.1013e-04 - mae: 0.0141\n",
      "Epoch 398: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Model fitting\n",
    "lstm_training = model.fit(X_train, \n",
    "                          y_train, \n",
    "                          batch_size=64, \n",
    "                          epochs=500, \n",
    "                          verbose=1, \n",
    "                          callbacks=my_callbacks, \n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25753a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24dde8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.0254 | Test RMSE: 0.0400\n"
     ]
    }
   ],
   "source": [
    "#### ERROR CALC\n",
    "\n",
    "\n",
    "# calculate rmse of loss function\n",
    "train_rmse_scaled = np.sqrt(model.evaluate(X_train, y_train, verbose=0))\n",
    "test_rmse_scaled = np.sqrt(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(f'Train RMSE: {train_rmse_scaled[0]:.4f} | Test RMSE: {test_rmse_scaled[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "990f7b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b3d032a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58119.578125</td>\n",
       "      <td>60185.093750</td>\n",
       "      <td>2065.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59697.195312</td>\n",
       "      <td>59441.089844</td>\n",
       "      <td>-256.105469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58730.476562</td>\n",
       "      <td>59001.792969</td>\n",
       "      <td>271.316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56289.289062</td>\n",
       "      <td>58233.589844</td>\n",
       "      <td>1944.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57569.074219</td>\n",
       "      <td>57056.648438</td>\n",
       "      <td>-512.425781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>19426.720703</td>\n",
       "      <td>20378.482422</td>\n",
       "      <td>951.761719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>19573.050781</td>\n",
       "      <td>20411.830078</td>\n",
       "      <td>838.779297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>19431.789062</td>\n",
       "      <td>20467.806641</td>\n",
       "      <td>1036.017578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>19312.095703</td>\n",
       "      <td>20485.060547</td>\n",
       "      <td>1172.964844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>19044.107422</td>\n",
       "      <td>20481.505859</td>\n",
       "      <td>1437.398438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           actual    prediction       spread\n",
       "0    58119.578125  60185.093750  2065.515625\n",
       "1    59697.195312  59441.089844  -256.105469\n",
       "2    58730.476562  59001.792969   271.316406\n",
       "3    56289.289062  58233.589844  1944.300781\n",
       "4    57569.074219  57056.648438  -512.425781\n",
       "..            ...           ...          ...\n",
       "313  19426.720703  20378.482422   951.761719\n",
       "314  19573.050781  20411.830078   838.779297\n",
       "315  19431.789062  20467.806641  1036.017578\n",
       "316  19312.095703  20485.060547  1172.964844\n",
       "317  19044.107422  20481.505859  1437.398438\n",
       "\n",
       "[318 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'actual': scaler.inverse_transform(y_test).flatten(),\n",
    "    'prediction': scaler.inverse_transform(y_pred).flatten()})\n",
    "\n",
    "df['spread'] = df['prediction'] - df['actual']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc7dd94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-square: 0.9539\n"
     ]
    }
   ],
   "source": [
    "print(f'R-square: {r2_score(df.actual, df.prediction):0.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd98eb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### PLOT RESULTS\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(df.actual, color='red', label='actual')\n",
    "ax[0].plot(df.prediction, color='blue', label='prediction')\n",
    "ax[1].hist(df.spread, bins=50, density=True, label='spread')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.suptitle('SPY LSTM Prediction');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6873fb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 60, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8c914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c916f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f770419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db3dfee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.copy(scaled_test_data)\n",
    "std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c533cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = []\n",
    "pr = np.array(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c56bcada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,5):\n",
    "    m=[]\n",
    "    m.append(std[318+i:378+i, 0])\n",
    "    m1 = np.array(m)\n",
    "    m2 = np.reshape(m1, (m1.shape[0], m1.shape[1], 1))\n",
    "    p = model.predict(m2)\n",
    "    std = np.append(std, p)\n",
    "    std = np.reshape(std, (-1, 1))\n",
    "    pr = np.append(pr, scaler.inverse_transform(p).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e1c8360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20425.25390625, 20691.89648438, 20943.57617188, 21214.50585938,\n",
       "       21504.55273438])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af1a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ee833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
